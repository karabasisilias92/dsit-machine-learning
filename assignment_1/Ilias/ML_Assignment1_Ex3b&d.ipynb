{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Assignment1_Ex3b&d.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2hpjKCcbgoH",
        "outputId": "3006715d-2c9f-4673-da3d-b21f72132a5b"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount ('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb_9r1oyiSJS",
        "outputId": "7456610e-ed8c-471d-839b-d8ae73a48331"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "\r\n",
        "def calculate_mean_for_class(dataframe, class_feature, class_value):\r\n",
        "  mean = np.array([])\r\n",
        "  features = dataframe.keys()\r\n",
        "  features = features.drop(class_feature)\r\n",
        "  for key in features:\r\n",
        "    mean = np.append(mean, [dataframe[key][df[class_feature] == class_value].sum()/len(df[key][df[class_feature] == class_value])])\r\n",
        "  return mean\r\n",
        "\r\n",
        "def calculate_covariance_matrix_for_class(dataframe, class_mean, class_feature, class_value):\r\n",
        "  features = dataframe.keys()\r\n",
        "  features = features.drop(class_feature)\r\n",
        "  dimension = len(features)\r\n",
        "  covariance = np.zeros(shape=(dimension, dimension))\r\n",
        "  for i in range(0, dimension):\r\n",
        "    for j in range(0, dimension):\r\n",
        "      buffer = (df[features[i]][df[class_feature] == class_value] - class_mean[i])*(df[features[j]][df[class_feature] == class_value] - class_mean[j])\r\n",
        "      covariance[i][j] = buffer.sum()/len(buffer)\r\n",
        "\r\n",
        "  return covariance\r\n",
        "\r\n",
        "def calculate_pdf_for_test_set(x, mean, covariance):\r\n",
        "  deter_covariance = np.linalg.det(covariance)\r\n",
        "  covariance_inv = np.linalg.inv(covariance)\r\n",
        "  dimension = len(mean)\r\n",
        "  pdf_x = (1 / ( (2*math.pi)**(dimension/2) * (deter_covariance**(1/2)))) * np.exp((-1/2)*((x.to_numpy()-mean).dot(covariance_inv)).dot((x.to_numpy()-mean).T))\r\n",
        "  return pdf_x.diagonal()\r\n",
        "\r\n",
        "def calculate_pdf_parzen_for_test_set(x_train, x_test):\r\n",
        "  x_train_array = x_train.to_numpy()\r\n",
        "  x_test_array = x_test.to_numpy()\r\n",
        "  N = x_train_array.shape[0]\r\n",
        "  h = math.sqrt(N) # square root of number of samples for class\r\n",
        "  dimension = x_train_array.shape[1]\r\n",
        "  marginal_pdfs = []\r\n",
        "  for i in range(0, dimension):\r\n",
        "    buffer = np.zeros(x_test_array.shape[0])\r\n",
        "    for xi in x_train_array[:][i]:\r\n",
        "      buffer = buffer + (1 / (math.sqrt(2*math.pi)*h)) * np.exp((-1 / (2*(h**2)))*(x_test_array[:,i] - xi)**2)\r\n",
        "    buffer = buffer / N\r\n",
        "    marginal_pdfs.append(buffer)\r\n",
        "\r\n",
        "  pdf_parzen = np.ones(marginal_pdfs[0].shape)\r\n",
        "  for marg_pdf in marginal_pdfs:\r\n",
        "    pdf_parzen = pdf_parzen * marg_pdf\r\n",
        "  return pdf_parzen\r\n",
        "\r\n",
        "def classify_and_calculate_epoch_accuracy(prop_class0, prop_class1, test_set, epoch):\r\n",
        "  classification = []\r\n",
        "  for i in range(0, len(prop_class0)):\r\n",
        "    if prop_class0[i] > prop_class1[i]:\r\n",
        "      classification.append(0)\r\n",
        "    else:\r\n",
        "      classification.append(1)\r\n",
        "  correct_classifications = 0\r\n",
        "  for i in range(0, len(classification)):\r\n",
        "    if classification[i] == test_set['Y'][epoch*len(classification)+i]:\r\n",
        "      correct_classifications += 1\r\n",
        "  accurracy_percentage = correct_classifications * 100 / len(classification)\r\n",
        "  return accurracy_percentage\r\n",
        "\r\n",
        "def calculate_accuracy_for_validation_epoch(train_set, test_set, prop_non_diabetes, prop_diabetes, epoch):\r\n",
        "  mean_class_non_diabetes = calculate_mean_for_class(train_set, 'Y', 0)\r\n",
        "  covariance_class_non_diabetes = calculate_covariance_matrix_for_class(train_set, mean_class_non_diabetes, 'Y', 0)\r\n",
        "  mean_class_diabetes = calculate_mean_for_class(train_set, 'Y', 1)\r\n",
        "  covariance_class_diabetes = calculate_covariance_matrix_for_class(train_set, mean_class_diabetes, 'Y', 1)\r\n",
        "  pdfs_test_set_class_non_diabetes = calculate_pdf_for_test_set(test_set.drop('Y', axis=1), mean_class_non_diabetes, covariance_class_non_diabetes)\r\n",
        "  prop_class_non_diabetes_test_set = pdfs_test_set_class_non_diabetes*prop_non_diabetes\r\n",
        "  pdfs_test_set_class_diabetes = calculate_pdf_for_test_set(test_set.drop('Y', axis=1), mean_class_diabetes, covariance_class_diabetes)\r\n",
        "  prop_class_diabetes_test_set = pdfs_test_set_class_diabetes*prop_diabetes\r\n",
        "  return classify_and_calculate_epoch_accuracy(prop_class_non_diabetes_test_set, prop_class_diabetes_test_set, test_set, epoch)\r\n",
        "\r\n",
        "def calculate_accuracy_parzen_for_validation_epoch(train_set, test_set, prop_non_diabetes, prop_diabetes, epoch):\r\n",
        "  pdfs_parzen_test_set_class_non_diabetes = calculate_pdf_parzen_for_test_set(train_set[train_set['Y'] == 0].drop('Y', axis=1), test_set.drop('Y', axis=1))\r\n",
        "  prop_class_non_diabetes_test_set = pdfs_parzen_test_set_class_non_diabetes*prop_non_diabetes\r\n",
        "  pdfs_parzen_test_set_class_diabetes = calculate_pdf_parzen_for_test_set(train_set[train_set['Y'] == 1].drop('Y', axis=1), test_set.drop('Y', axis=1))\r\n",
        "  prop_class_diabetes_test_set = pdfs_parzen_test_set_class_diabetes*prop_diabetes\r\n",
        "  return classify_and_calculate_epoch_accuracy(prop_class_non_diabetes_test_set, prop_class_diabetes_test_set, test_set, epoch)\r\n",
        "\r\n",
        "\r\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/pima-indians-diabetes.data',delimiter=',', encoding='ISO-8859–1', names=['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'Y'])\r\n",
        "k = math.ceil(df.index.shape[0] / 8) # 8-Fold cross validation\r\n",
        "class_non_diabetes_prop = df[df['Y'] == 0].shape[0] / df.index.shape[0]\r\n",
        "class_diabete_prop = df[df['Y'] == 1].shape[0] / df.index.shape[0]\r\n",
        "\r\n",
        "##### Pdfs are gaussian, with non-diagonal covariance matrices\r\n",
        "accurracy_percentages = []\r\n",
        "for i in range(0, 8):\r\n",
        "  accurracy_percentages.append(calculate_accuracy_for_validation_epoch(df.drop(df.index[i*k:(i+1)*k]), df[i*k:(i+1)*k], class_non_diabetes_prop, class_diabete_prop, i))\r\n",
        "\r\n",
        "print(accurracy_percentages)\r\n",
        "average_accuracy = sum(accurracy_percentages) / len(accurracy_percentages)\r\n",
        "print(round(average_accuracy, 2))\r\n",
        "\r\n",
        "#### Components of the feature vectors are mutually statistically independent (the usual naïve Bayes approach). Marginal pdfs 1-d Parzen windows, gaussian kernels\r\n",
        "accurracy_percentages_parzen = []\r\n",
        "for i in range(0, 8):\r\n",
        "  accurracy_percentages_parzen.append(calculate_accuracy_parzen_for_validation_epoch(df.drop(df.index[i*k:(i+1)*k]), df[i*k:(i+1)*k], class_non_diabetes_prop, class_diabete_prop, i))\r\n",
        "\r\n",
        "print(accurracy_percentages_parzen)\r\n",
        "average_accuracy_parzen = sum(accurracy_percentages_parzen) / len(accurracy_percentages_parzen)\r\n",
        "print(round(average_accuracy_parzen, 2))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[72.91666666666667, 75.0, 72.91666666666667, 72.91666666666667, 76.04166666666667, 78.125, 76.04166666666667, 73.95833333333333]\n",
            "74.74\n",
            "[36.458333333333336, 43.75, 55.208333333333336, 52.083333333333336, 51.041666666666664, 47.916666666666664, 53.125, 48.958333333333336]\n",
            "48.57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t18gxon55K_4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}